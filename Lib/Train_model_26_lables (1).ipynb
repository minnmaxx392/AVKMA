{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a-GmfW-7quP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c960105-6a3f-4c3b-9207-9a1220e69792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-2754377aae79>:55: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  y_train = np.where(y_train == '[0]', '0', y_train)  # Xử lý chuỗi '[0]' thành '0'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy as np\n",
        "import timeit\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from keras.layers import Input, Dense, Flatten, Dropout\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "SIZE = 27\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "PADDING = 46\n",
        "\n",
        "def load_data(data_train, data_val, data_test):\n",
        "    train = pd.read_csv(data_train)\n",
        "    val = pd.read_csv(data_val)\n",
        "    test = pd.read_csv(data_test)\n",
        "    return train, val, test\n",
        "\n",
        "def preprocess_data(data, max_values_dict):\n",
        "    x = data.drop(['file_name', 'label', 'category_name', 'category_encoding'], axis=1)\n",
        "    y = data['category_encoding']\n",
        "\n",
        "    for feature in x.columns:\n",
        "        max_value = max_values_dict.get(feature, 1)\n",
        "        if max_value == 0:\n",
        "            x[feature] = 0\n",
        "        else:\n",
        "            x[feature] = x[feature] / max_value\n",
        "\n",
        "    return x, y\n",
        "\n",
        "data = []\n",
        "\n",
        "def prepare_data(train, val, test, max_values_dict):\n",
        "\n",
        "    x_train, y_train = preprocess_data(train, max_values_dict)\n",
        "    x_val, y_val = preprocess_data(val, max_values_dict)\n",
        "    x_test, y_test = preprocess_data(test, max_values_dict)\n",
        "\n",
        "\n",
        "    y_train = np.array(y_train)  # Chuyển đổi y_train thành một mảng numpy\n",
        "    y_train = np.where(y_train == '[0]', '0', y_train)  # Xử lý chuỗi '[0]' thành '0'\n",
        "\n",
        "    SIZE = 27\n",
        "    PADDING = 46\n",
        "\n",
        "    x_train_deep = np.concatenate((x_train[:], np.zeros((x_train[:].shape[0], PADDING))), 1)\n",
        "    x_val_deep = np.concatenate((x_val[:], np.zeros((x_val[:].shape[0], PADDING))), 1)\n",
        "    x_test_deep = np.concatenate((x_test[:], np.zeros((x_test[:].shape[0], PADDING))), 1)\n",
        "\n",
        "    x_train_deep = x_train_deep.reshape(x_train_deep.shape[0], SIZE, SIZE, 1)\n",
        "    x_val_deep = x_val_deep.reshape(x_val_deep.shape[0], SIZE, SIZE, 1)\n",
        "    x_test_deep = x_test_deep.reshape(x_test_deep.shape[0], SIZE, SIZE, 1)\n",
        "\n",
        "    y_train_deep = to_categorical(y_train, 30)\n",
        "    y_val_deep = to_categorical(y_val, 30)\n",
        "\n",
        "    return x_train_deep, y_train_deep, x_val_deep, y_val_deep, x_test_deep, y_test\n",
        "\n",
        "def build_CNN_model(SIZE):\n",
        "    deep_input = Input(shape=(SIZE, SIZE, 1))\n",
        "    conv1 = Conv2D(32, kernel_size=2, activation='relu', padding=\"same\", input_shape=(SIZE, SIZE, 1))(deep_input)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(32, kernel_size=2, activation='relu', padding=\"same\")(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(64, kernel_size=2, activation='relu', padding=\"same\")(pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    flatten = Flatten()(pool3)\n",
        "    deep = Dense(1024, activation='relu')(flatten)\n",
        "    deep = Dropout(0.3)(deep)\n",
        "    deep = Dense(512, activation='relu')(deep)\n",
        "    deep = Dropout(0.3)(deep)\n",
        "    output = Dense(30, activation='softmax')(deep)\n",
        "    model_CNN_PE = Model(inputs=deep_input, outputs=output)\n",
        "    model_CNN_PE.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Thêm callback \"early stopping\"\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
        "\n",
        "    return model_CNN_PE\n",
        "\n",
        "def train_model(model, x_train, y_train, x_val, y_val):\n",
        "    history = model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_val, y_val))\n",
        "    return history\n",
        "\n",
        "def save_model(model, file_path):\n",
        "    model.save(file_path)\n",
        "\n",
        "def plot_training_history(history):\n",
        "    # Plot accuracy\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    # Plot loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true = y_test.values\n",
        "    print(\"Accuracy Score:\", accuracy_score(y_true, y_pred_classes))\n",
        "    print(\"Precision Score:\", precision_score(y_true, y_pred_classes, average='weighted'))\n",
        "    print(\"Recall Score:\", recall_score(y_true, y_pred_classes, average='weighted'))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred_classes, average='weighted'))\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred_classes))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred_classes))\n",
        "\n",
        "\n",
        "# Chạy chương trình\n",
        "data_train = r\"/content/drive/MyDrive/Data/New_data_26/data_new_combined_26.csv\"\n",
        "data_val = r\"/content/drive/MyDrive/Data/New_data_26/split9.csv\"\n",
        "data_test = r\"/content/drive/MyDrive/Data/New_data_26/split10.csv\"\n",
        "train, val, test = load_data(data_train, data_val, data_test)\n",
        "\n",
        "max_values_df = pd.read_csv(\"/content/drive/MyDrive/Data/New_data_26/max_data_new.csv\")\n",
        "max_values_dict = max_values_df.set_index('Feature')['Max Value'].to_dict()\n",
        "\n",
        "x_train_deep, y_train_deep, x_val_deep, y_val_deep, x_test_deep, y_test = prepare_data(train, val, test,\n",
        "                                                                                       max_values_dict)\n",
        "\n",
        "SIZE = 27\n",
        "# model_CNN_PE = build_CNN_model(SIZE)\n",
        "\n",
        "# history = train_model(model_CNN_PE, x_train_deep, y_train_deep, x_val_deep, y_val_deep)\n",
        "\n",
        "# history_dict = history.history\n",
        "\n",
        "# # Lưu `history` vào tệp JSON\n",
        "# with open('history.json', 'w') as f:\n",
        "#     json.dump(history_dict, f)\n",
        "\n",
        "# save_model(model_CNN_PE, '/content/model_12_07_26_lables.h5')\n",
        "\n",
        "# plot_training_history(history)\n",
        "\n",
        "# evaluate_model(model_CNN_PE, x_test_deep, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/DL_Category.h5\")\n",
        "\n",
        "\n",
        "data_train = r\"/content/drive/MyDrive/Data/New_data_last_last/data_raw.csv\"\n",
        "data_val = r\"/content/drive/MyDrive/Data/New_data_last_last/aasplit_9.csv\"\n",
        "data_test = r\"/content/drive/MyDrive/Data/New_data_last/aasplit_8.csv\"\n",
        "\n",
        "train, val, test = load_data(data_train, data_val, data_test)\n",
        "\n",
        "x_train_deep, y_train_deep, x_val_deep, y_val_deep, x_test_deep, y_test = prepare_data(train, val, test, exportFunction,\n",
        "                                                                                       max_values_dict)\n",
        "\n",
        "model.fit(x_train_deep, y_train_deep, epochs=50, batch_size=32, validation_data=(x_val_deep, y_val_deep))\n",
        "\n",
        "model.save('test.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0roCDi81kZD",
        "outputId": "bc6e4f89-5c81-4f83-eb4f-d62674b95dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "31/31 [==============================] - 4s 61ms/step - loss: 0.7031 - accuracy: 0.8649 - val_loss: 0.5738 - val_accuracy: 0.7956\n",
            "Epoch 2/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.3739 - accuracy: 0.9093 - val_loss: 0.6797 - val_accuracy: 0.7847\n",
            "Epoch 3/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.2793 - accuracy: 0.9173 - val_loss: 0.5142 - val_accuracy: 0.8317\n",
            "Epoch 4/50\n",
            "31/31 [==============================] - 2s 52ms/step - loss: 0.2251 - accuracy: 0.9355 - val_loss: 0.6525 - val_accuracy: 0.8408\n",
            "Epoch 5/50\n",
            "31/31 [==============================] - 2s 72ms/step - loss: 0.2031 - accuracy: 0.9435 - val_loss: 0.5050 - val_accuracy: 0.8440\n",
            "Epoch 6/50\n",
            "31/31 [==============================] - 3s 92ms/step - loss: 0.1719 - accuracy: 0.9446 - val_loss: 0.7129 - val_accuracy: 0.8381\n",
            "Epoch 7/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.1505 - accuracy: 0.9546 - val_loss: 0.6630 - val_accuracy: 0.8513\n",
            "Epoch 8/50\n",
            "31/31 [==============================] - 2s 52ms/step - loss: 0.1210 - accuracy: 0.9627 - val_loss: 0.8022 - val_accuracy: 0.8374\n",
            "Epoch 9/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.1103 - accuracy: 0.9677 - val_loss: 0.6904 - val_accuracy: 0.8490\n",
            "Epoch 10/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0987 - accuracy: 0.9698 - val_loss: 0.8623 - val_accuracy: 0.8400\n",
            "Epoch 11/50\n",
            "31/31 [==============================] - 3s 92ms/step - loss: 0.0864 - accuracy: 0.9718 - val_loss: 0.9177 - val_accuracy: 0.8340\n",
            "Epoch 12/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0834 - accuracy: 0.9728 - val_loss: 0.8650 - val_accuracy: 0.8422\n",
            "Epoch 13/50\n",
            "31/31 [==============================] - 2s 52ms/step - loss: 0.0692 - accuracy: 0.9808 - val_loss: 0.9070 - val_accuracy: 0.8424\n",
            "Epoch 14/50\n",
            "31/31 [==============================] - 2s 51ms/step - loss: 0.0649 - accuracy: 0.9798 - val_loss: 1.0539 - val_accuracy: 0.8357\n",
            "Epoch 15/50\n",
            "31/31 [==============================] - 2s 52ms/step - loss: 0.0615 - accuracy: 0.9808 - val_loss: 0.9298 - val_accuracy: 0.8391\n",
            "Epoch 16/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0670 - accuracy: 0.9829 - val_loss: 1.0647 - val_accuracy: 0.8373\n",
            "Epoch 17/50\n",
            "31/31 [==============================] - 2s 69ms/step - loss: 0.0563 - accuracy: 0.9849 - val_loss: 1.0483 - val_accuracy: 0.8424\n",
            "Epoch 18/50\n",
            "31/31 [==============================] - 3s 89ms/step - loss: 0.0484 - accuracy: 0.9839 - val_loss: 1.0639 - val_accuracy: 0.8406\n",
            "Epoch 19/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0707 - accuracy: 0.9829 - val_loss: 0.9735 - val_accuracy: 0.8480\n",
            "Epoch 20/50\n",
            "31/31 [==============================] - 2s 52ms/step - loss: 0.0465 - accuracy: 0.9849 - val_loss: 1.2134 - val_accuracy: 0.8358\n",
            "Epoch 21/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0495 - accuracy: 0.9869 - val_loss: 0.9884 - val_accuracy: 0.8506\n",
            "Epoch 22/50\n",
            "31/31 [==============================] - 2s 78ms/step - loss: 0.0552 - accuracy: 0.9778 - val_loss: 1.0006 - val_accuracy: 0.8422\n",
            "Epoch 23/50\n",
            "31/31 [==============================] - 2s 58ms/step - loss: 0.0468 - accuracy: 0.9808 - val_loss: 1.1921 - val_accuracy: 0.8398\n",
            "Epoch 24/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0538 - accuracy: 0.9859 - val_loss: 0.9975 - val_accuracy: 0.8529\n",
            "Epoch 25/50\n",
            "31/31 [==============================] - 2s 55ms/step - loss: 0.0513 - accuracy: 0.9879 - val_loss: 1.1111 - val_accuracy: 0.8482\n",
            "Epoch 26/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0498 - accuracy: 0.9829 - val_loss: 1.1595 - val_accuracy: 0.8439\n",
            "Epoch 27/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0593 - accuracy: 0.9839 - val_loss: 1.0242 - val_accuracy: 0.8506\n",
            "Epoch 28/50\n",
            "31/31 [==============================] - 2s 74ms/step - loss: 0.0719 - accuracy: 0.9748 - val_loss: 1.1243 - val_accuracy: 0.8329\n",
            "Epoch 29/50\n",
            "31/31 [==============================] - 2s 51ms/step - loss: 0.0510 - accuracy: 0.9829 - val_loss: 1.3786 - val_accuracy: 0.8325\n",
            "Epoch 30/50\n",
            "31/31 [==============================] - 2s 52ms/step - loss: 0.0727 - accuracy: 0.9808 - val_loss: 1.2286 - val_accuracy: 0.8418\n",
            "Epoch 31/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0464 - accuracy: 0.9849 - val_loss: 1.2965 - val_accuracy: 0.8435\n",
            "Epoch 32/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0289 - accuracy: 0.9919 - val_loss: 1.2838 - val_accuracy: 0.8435\n",
            "Epoch 33/50\n",
            "31/31 [==============================] - 2s 54ms/step - loss: 0.0432 - accuracy: 0.9849 - val_loss: 0.9515 - val_accuracy: 0.8566\n",
            "Epoch 34/50\n",
            "31/31 [==============================] - 2s 72ms/step - loss: 0.0506 - accuracy: 0.9849 - val_loss: 1.0717 - val_accuracy: 0.8514\n",
            "Epoch 35/50\n",
            "31/31 [==============================] - 3s 92ms/step - loss: 0.0419 - accuracy: 0.9849 - val_loss: 1.1163 - val_accuracy: 0.8471\n",
            "Epoch 36/50\n",
            "31/31 [==============================] - 2s 50ms/step - loss: 0.0359 - accuracy: 0.9889 - val_loss: 1.3573 - val_accuracy: 0.8422\n",
            "Epoch 37/50\n",
            "31/31 [==============================] - 2s 52ms/step - loss: 0.0352 - accuracy: 0.9919 - val_loss: 1.4284 - val_accuracy: 0.8399\n",
            "Epoch 38/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0283 - accuracy: 0.9919 - val_loss: 1.5909 - val_accuracy: 0.8363\n",
            "Epoch 39/50\n",
            "31/31 [==============================] - 2s 52ms/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 1.6370 - val_accuracy: 0.8338\n",
            "Epoch 40/50\n",
            "31/31 [==============================] - 2s 60ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 1.6845 - val_accuracy: 0.8335\n",
            "Epoch 41/50\n",
            "31/31 [==============================] - 3s 92ms/step - loss: 0.0291 - accuracy: 0.9869 - val_loss: 1.6924 - val_accuracy: 0.8336\n",
            "Epoch 42/50\n",
            "31/31 [==============================] - 2s 51ms/step - loss: 0.0250 - accuracy: 0.9909 - val_loss: 1.6012 - val_accuracy: 0.8375\n",
            "Epoch 43/50\n",
            "31/31 [==============================] - 2s 52ms/step - loss: 0.0490 - accuracy: 0.9889 - val_loss: 1.2453 - val_accuracy: 0.8403\n",
            "Epoch 44/50\n",
            "31/31 [==============================] - 2s 51ms/step - loss: 0.0660 - accuracy: 0.9778 - val_loss: 1.1356 - val_accuracy: 0.8464\n",
            "Epoch 45/50\n",
            "31/31 [==============================] - 2s 52ms/step - loss: 0.0503 - accuracy: 0.9859 - val_loss: 1.3185 - val_accuracy: 0.8465\n",
            "Epoch 46/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0267 - accuracy: 0.9899 - val_loss: 1.3339 - val_accuracy: 0.8427\n",
            "Epoch 47/50\n",
            "31/31 [==============================] - 3s 90ms/step - loss: 0.0234 - accuracy: 0.9909 - val_loss: 1.4195 - val_accuracy: 0.8455\n",
            "Epoch 48/50\n",
            "31/31 [==============================] - 2s 62ms/step - loss: 0.0312 - accuracy: 0.9859 - val_loss: 1.3221 - val_accuracy: 0.8477\n",
            "Epoch 49/50\n",
            "31/31 [==============================] - 2s 51ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 1.1615 - val_accuracy: 0.8427\n",
            "Epoch 50/50\n",
            "31/31 [==============================] - 2s 53ms/step - loss: 0.0275 - accuracy: 0.9899 - val_loss: 1.2685 - val_accuracy: 0.8482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"/content/model_12_07_26_lables.h5\")\n",
        "y_pred = model.predict(x_train_deep)\n",
        "\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = y_train_deep\n",
        "print(\"Accuracy Score:\", accuracy_score(y_true, y_pred_classes))\n",
        "print(\"Precision Score:\", precision_score(y_true, y_pred_classes, average='weighted'))\n",
        "print(\"Recall Score:\", recall_score(y_true, y_pred_classes, average='weighted'))\n",
        "print(\"F1 Score:\", f1_score(y_true, y_pred_classes, average='weighted'))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "WnT6xxMkOQLj",
        "outputId": "dac42150-65fa-4391-aa06-44454f7a1525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4986/4986 [==============================] - 17s 2ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-58989ba7c77d>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_deep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred_classes\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yurS325SPw0B",
        "outputId": "db3c5ec4-c80a-44a3-8398-a4e32f0053a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KUGCpQ6IenR",
        "outputId": "96b2586d-b85a-4291-ad70-7946d812cd07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 27, 27, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 27, 27, 32)        160       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 13, 13, 32)        4128      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 6, 6, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 6, 6, 64)          8256      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 3, 3, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              590848    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 30)                15390     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,143,582\n",
            "Trainable params: 1,143,582\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "vUoZZjAE73bH",
        "outputId": "ec06c831-231b-48ac-afbc-592ab592395f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    # Plot accuracy\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    plt.savefig(\"Accurancyv410.png\")\n",
        "    # Plot loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    plt.savefig(\"Lossv410.png\")\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "C2x3v6uIXHRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, x_test, y_test):\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true = y_test.values\n",
        "    print(\"Accuracy Score:\", accuracy_score(y_true, y_pred_classes))\n",
        "    print(\"Precision Score:\", precision_score(y_true, y_pred_classes, average='weighted'))\n",
        "    print(\"Recall Score:\", recall_score(y_true, y_pred_classes, average='weighted'))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred_classes, average='weighted'))\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred_classes))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred_classes))\n",
        "    print(y_pred_classes)\n",
        "evaluate_model(model_CNN_PE, x_test_deep, y_test)"
      ],
      "metadata": {
        "id": "STzwv7xvFvAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_CNN_PE.predict(x_test_deep)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = y_test.values\n",
        "print(\"Accuracy Score:\", accuracy_score(y_true, y_pred_classes))\n",
        "print(\"Precision Score:\", precision_score(y_true, y_pred_classes, average='weighted'))\n",
        "print(\"Recall Score:\", recall_score(y_true, y_pred_classes, average='weighted'))\n",
        "print(\"F1 Score:\", f1_score(y_true, y_pred_classes, average='weighted'))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred_classes))\n",
        "print(y_pred_classes)"
      ],
      "metadata": {
        "id": "t0iHI9DDzgg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val.iloc[:, 3].value_counts()"
      ],
      "metadata": {
        "id": "9bI0atmL0XN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "uRi-8tDG0mks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "PADDING = 46  # Thay bằng giá trị PADDING thích hợp\n",
        "SIZE = 27  # Thay bằng giá trị SIZE thích hợp\n",
        "\n",
        "def load_test_dataset(filepath):\n",
        "    test_new = pd.read_csv(filepath)\n",
        "    x_test_new = test_new.drop(['file_name', 'label', 'category_name', 'category_encoding']  + exportFunction, axis=1)\n",
        "    y_test_new = test_new['category_encoding']\n",
        "    return x_test_new, y_test_new\n",
        "\n",
        "def standardize_data(x_test_new, max_values_dict):\n",
        "    for feature in x_test_new.columns:\n",
        "        max_value = max_values_dict.get(feature, 1)\n",
        "        if max_value == 0:\n",
        "            x_test_new[feature] = 0\n",
        "        else:\n",
        "            x_test_new[feature] = x_test_new[feature] / max_value\n",
        "    return x_test_new\n",
        "\n",
        "def preprocess_data(x_test_new, y_test_new):\n",
        "    x_test_new_deep = np.concatenate((x_test_new[:], np.zeros((x_test_new[:].shape[0], PADDING))), 1)\n",
        "    x_test_new_deep = x_test_new_deep.reshape(x_test_new_deep.shape[0], SIZE, SIZE, 1)\n",
        "    return x_test_new_deep, y_test_new\n",
        "\n",
        "def predict_accuracy(model_path, x_test_new_deep, y_test_new):\n",
        "    model = load_model(model_path)\n",
        "    y_pred = model.predict(x_test_new_deep)\n",
        "    y_pred = np.argmax(y_pred, axis=-1)\n",
        "    accuracy = np.sum(y_pred == y_test_new) / len(y_pred)\n",
        "    print(\"kết quả nhận dạng: \", accuracy)\n",
        "    return accuracy\n",
        "\n",
        "def preprocess_and_predict(filepath, max_values_dict, model):\n",
        "    x_test_new, y_test_new = load_test_dataset(filepath)\n",
        "    x_test_new = standardize_data(x_test_new, max_values_dict)\n",
        "    x_test_new_deep, y_test_new = preprocess_data(x_test_new, y_test_new)\n",
        "    accuracy = predict_accuracy(model, x_test_new_deep, y_test_new)\n",
        "    return accuracy\n",
        "\n",
        "# Sử dụng hàm preprocess_and_predict\n",
        "filepath = r\"/content/drive/MyDrive/Data/New_data_last/aasplit_10.csv\"\n",
        "max_values_df = pd.read_csv(\"/content/drive/MyDrive/Data/New_data_last/max_data.csv\")\n",
        "max_values_dict = max_values_df.set_index('Feature')['Max Value'].to_dict()\n",
        "model_path = '/content/trained_model_CNN_classification_ver410.h5'  # Thay bằng mô hình CNN thích hợp\n",
        "\n",
        "accuracy = preprocess_and_predict(filepath, max_values_dict, model_path)\n"
      ],
      "metadata": {
        "id": "WWo0KF7EF551"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_new = pd.read_csv(r\"/content/drive/MyDrive/Data/New_data_last/aasplit_10.csv\")\n",
        "x_test_new = test_new.drop(['file_name', 'label', 'category_name', 'category_encoding']+ exportFunction, axis=1)\n",
        "y_test_new = test_new['category_encoding']\n",
        "\n",
        "print(x_test_new.shape)\n",
        "# Tiêu chuẩn hóa dữ liệu bằng Standard Scaling\n",
        "for feature in x_test_new.columns:\n",
        "  max_value = max_values_dict.get(feature, 1)  # Lấy giá trị max từ dict, nếu không có thì mặc định là 1\n",
        "  if max_value == 0:\n",
        "    x_test_new[feature] = 0\n",
        "  else:\n",
        "    x_test_new[feature] = x_test_new[feature] / max_value\n",
        "#print(x_val)\n",
        "\n",
        "x_test_new_deep = np.concatenate((x_test_new[:], np.zeros((x_test_new[:].shape[0], PADDING))),1)\n",
        "\n",
        "\n",
        "x_test_new_deep = x_test_new_deep.reshape(x_test_new_deep.shape[0],SIZE, SIZE, 1)\n",
        "\n",
        "\n",
        "print(x_test_new_deep)\n",
        "print(y_test_new.shape)\n",
        "#predict\n",
        "y_pred = model_CNN_PE.predict(x_test_new_deep)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "print(\"kết quả nhận dạng: \",np.sum(y_pred == y_test_new) / len(y_pred))"
      ],
      "metadata": {
        "id": "O_uYy2jXNdgz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}